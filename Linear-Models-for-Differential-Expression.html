<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Linear Models for Differential Expression</title>
    <meta charset="utf-8" />
    <meta name="author" content="Alex Sanchez (asanchez@ub.edu)" />
    <meta name="date" content="2021-05-18" />
    <script src="libs/header-attrs-2.7/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/metropolis.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/metropolis-fonts.css" rel="stylesheet" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Linear Models for Differential Expression
### Alex Sanchez (<a href="mailto:asanchez@ub.edu" class="email">asanchez@ub.edu</a>)
### 2021-05-18

---






# Outline

.columnwide[
  ### 1) [A recap on linear models](#review)
  ### 2) [Linear models with R](#lm)
  ### 3) [Linear models for microarray data](#limma)
  ### 4) [Exercises](#exercises)
]

---

class: inverse, middle, center

name: review

# A recap on linear models &lt;a id="review"&gt;&lt;/a&gt;


---


# Linear models. Introductory Example 1

- Consider a study comparing __two diets__ in mice, a "standard" vs a "high-fat" one.

- If we consider that the weight of the animals is a linear function of the diets, the following linear model can be written:

$$ 
Y_i = \beta_0 + \beta_1 x_i + \varepsilon_i, i=1,\dots,N 
$$
- where:
  - `\(Y_i\)` represents the weights of the i-th experimental unit-
      &lt;!-- - The term *experimental unit* describes the `\(N\)` different entities from which we obtain a measurement. In this case this is "mice". --&gt;
  - `\(x_i\)` is equal to 1 only when mouse `\(i\)` receives the high fat diet and 0 when it receives the standard diet.
      &lt;!-- - We call thees variables *indicator variables* since they simply indicate if the experimental unit had a certain characteristic or not. --&gt;
      
- The main goal of the study are:

  - To estimate the mean weight of mice after having been nurrished with each diet
  - To compare the difference in weight between the standard and "high fat" diets.

---

# Linear models. Introductory Example 2

- Consider a study on the effect of estrogen on the genes in ER+ breast cancer cells over time. 

- After serum starvation of __eight__ samples, researchers treated four samples exposing them to estrogen and left the remaining four samples untreated.

- For each sample they measured mRNA transcript abundance  
  - after 10 hours for half of the samples (two treated and two untreated).
  - and 48 hours for the other half (two treated and two untreated).

- Their goal was to compare te effect of estrogen addition on gene expression as well as how this effect differs when 10 or 48 hours had passed.
---

# From experimental design to linear models

- Eamples (1) and (2) have clearly different Experimental Designs but,

  - Both can be represented using an appropriate linear model.
  
      - Notice however that, for Example 2, we build _one distinct model for each gene_.
  
  - This representation will guide the analysis to estimate the effects, and to compare treatments or diets.

- Linear models provide a convenient setting to describe experimental designs and to analyze data that has been obtained from experiments performed according to the design they describe (more about this later)

---

# The general linear model

![](images/linMod3.png)

- Linear models assume a linear relation between a _response_ "dependent") variable, and one or more _explanatory_ (or "independent") variables(s).

- Many common problems can be re-written as linear models.

  [Common statistical tests are linear models](https://lindeloev.github.io/tests-as-linear/)

---

# Comparison of 2 groups = t-test
&lt;p&gt;
.center[ 
&lt;img align = "center" src="images/linMod1.png" width = "90%"&gt; 
&lt;p&gt;
&lt;img align = "center" src="images/linMod2.png" width = "80%"&gt; 
 ]

---

# Comparison of three groups (ANOVA)

&lt;p&gt;
.center[ 
&lt;img align = "center" src="images/linMod5.png" width = "90%"&gt; 
&lt;p&gt;
&lt;img align = "center" src="images/linMod4.png" width = "80%"&gt; 
 ]

---

# Estimating a linear model

- For linear models to be useful, we have to _estimate_ the unknown values `\(\beta_i\)`.

- The standard approach in science is to find the values that minimize the distance of the fitted model to the data. 

- The following is called the least squares (LS) equation:

&lt;!-- $$ --&gt;
&lt;!-- RSS = \sum_{i=1}^n \left\{  y_i - \left(\beta_0 + \beta_1 x_i \right)\right\}^2 --&gt;
&lt;!-- $$ --&gt;

.center[ 
&lt;img align = "center" src="images/linMod7RSS.png" width = "50%"&gt;
]
- This quantity is called the residual sum of squares (RSS). 

- Once we find the values that minimize the RSS, we will call the values the _least squares estimates (LSE)_ and denote them with  `\(\hat \beta_i\)`.


---

# Matrix notation for linear models

- Linear models can be written as:
  - explicit expressions (above) or 
  - using matrix notation (below)

.center[ 
&lt;img align = "center" src="images/linMod8MatrixNotation.png" width = "90%"&gt;
]

- Matrix notation is generally preferred.
  - More compact notation
  - More efficient computations.
  
---

# Computers prefer matrices

- Many languages are ready to perform matrix operations in parallel which yields a smaller number of operations and a smaller computing time 
- Higher efficency is also due to the implicit use of matrix algebra libraries.

&lt;p&gt;

![](images/captura_007.png)

---

# Two groups in matrix notation

&lt;p&gt;
.center[
![](images/captura_008.png)
]

This _linear model_ can be written in more compact notations as:

$$
\mathbf{Y}=\mathbf{X}\boldsymbol{\beta}+\boldsymbol{\varepsilon}
$$
The matrix \mathbf{X} is called the _design matrix_
---

# Three groups in matrix notation

.center[
![](images/captura_009.png)
]

---

# Fitting linear models

- A linear model can be _fitted_ by solving the _normal equations_

![](images/captura_010.png)

- Error estimates for the model coefficients can also be obtained:

![](images/captura_012.png)

---

# Significance testing with linear models.

- Assuming a series of assumptions hold

  - Variance homogeneity
  - Linearity of relations
  - Independence and _normality_ of error terms
  
- A test can be built to test the significance of the model coefficients


![](images/captura_011.png)


&lt;!-- --- --&gt;

&lt;!-- # The power of linear models: crossed designs --&gt;

&lt;!-- ![](images/captura_014.png) --&gt;

&lt;!-- We assume effects are additive! --&gt;

&lt;!-- --- --&gt;

&lt;!-- # Crossed designs with interaction --&gt;

&lt;!-- ![](images/captura_015.png) --&gt;

&lt;!-- Interaction shows additional to additive effects --&gt;

---

# How is a linear models usually applied?

- Estimating the parameters values to know mean effect of one factor or of each level od this factor.
  
- Comparing the parameters' values  to decide if different treatments have the same effect, or have any effect at all.
  
- Adjusting the effect of distinct covariables, which may not be of direct interest ion the studyu but whose effect may interfere in the relation between the response variable and the explanatory ones.
  
  - A common quote in science papers: *"The study of ... controlled for age, race, and sex ..."*,
  - Usually, what it means is that we have included thes variables in the model expecting the variability that they explain is separated from that explained buy the other components of the model.
        ![](images/captura_016.png)


---

class: inverse, middle, center

name: review

# Linear models in R &lt;a id="lm"&gt;&lt;/a&gt;


---

# Fitting linear models in R

- In practice, when using R, _we rarely fit a model by solving the normal equations_

- The usual, and most practical way to do it, is to use `lm` function.

- The `lm` function requires

  - Either a `formula` relating the variables to be included in a linear model
  
  - Or a design matrix, that we can create using the `model.matrix` function, and which, implicitly, defines that model.

---

# The importance of the design matrix

- The choice of design matrix is a _critical step_ in linear modeling as

  - it encodes which coefficients will be fit in the model, 
  - and the inter-relationship between the samples.
  
- Defining which design matrix we use is equivalent to defining the parameters of the model (or the model's _parametrization_).

  - The same data can be modelled differently, if the parameters are assigned different meanings.

  - In practice this represents using distinct design matrices
  
- A typical example: How does the meaning of a one-way factor ANOVA change if we consider a model with or without an intercept?
  - How is it reflected in the design matrix?

---

# Model matrix for two groups

- Suppose we have two groups, 1 and 2, with two samples each.
- We might start to encode this experimental design like so:


```r
x &lt;- c(1,1,2,2)
f &lt;- formula(~ x)
model.matrix(f)
```

```
##   (Intercept) x
## 1           1 1
## 2           1 1
## 3           1 2
## 4           1 2
## attr(,"assign")
## [1] 0 1
```

---

# Model matrix for two groups (2)

- Note that an intercept will be included by default, so the formula could equivalently be written: `~ x + 1`.

- We can then inspect the design matrix which is formed by this:


```r
model.matrix(f)
```

```
##   (Intercept) x
## 1           1 1
## 2           1 1
## 3           1 2
## 4           1 2
## attr(,"assign")
## [1] 0 1
```

---

# model.matrix requires factors

- Note, this is not the design matrix we wanted.
- We should instead first tell R that these values should not be interpreted numerically, but as different levels of a factor variable:


```r
x &lt;- factor(c(1,1,2,2))
model.matrix(~ x)
```

```
##   (Intercept) x2
## 1           1  0
## 2           1  0
## 3           1  1
## 4           1  1
## attr(,"assign")
## [1] 0 1
## attr(,"contrasts")
## attr(,"contrasts")$x
## [1] "contr.treatment"
```

- Now we have achieved the correct design matrix.
- Or have we?

---

# The role of the intercept term

- Note that the previous matrix has one intercept column and one group column although there are two groups indeed.

  - The first group's values are represented by the basal or "overall mean".
  - The second group's are represented by one column.

- An alternative representation is possible setting the intercept to zero.


```r
x &lt;- factor(c(1,1,2,2))
model.matrix(~ x + 0)
```

```
##   x1 x2
## 1  1  0
## 2  1  0
## 3  0  1
## 4  0  1
## attr(,"assign")
## [1] 1 1
## attr(,"contrasts")
## attr(,"contrasts")$x
## [1] "contr.treatment"
```

- Both representations are equivalent and for one-factor designs it's up to you which one to choose

---

# Design matrix for more than 2 groups

- How is the design matrix for an experiment with 3 groups?
- We proceed like in the previous case


```r
x &lt;- factor(c(1,1,2,2,3,3))
model.matrix(~ x)
```

```
##   (Intercept) x2 x3
## 1           1  0  0
## 2           1  0  0
## 3           1  1  0
## 4           1  1  0
## 5           1  0  1
## 6           1  0  1
## attr(,"assign")
## [1] 0 1 1
## attr(,"contrasts")
## attr(,"contrasts")$x
## [1] "contr.treatment"
```

- Again the first group is implicit in the intercept but it can be set explicitly by setting the intercept to zero.

---

# An alternative parametrization

-   An alternate formulation of design matrix is possible by specifying `+0` in the formula:


```r
x &lt;- factor(c(1,1,2,2,3,3))
model.matrix(~ x + 0)
```

```
##   x1 x2 x3
## 1  1  0  0
## 2  1  0  0
## 3  0  1  0
## 4  0  1  0
## 5  0  0  1
## 6  0  0  1
## attr(,"assign")
## [1] 1 1 1
## attr(,"contrasts")
## attr(,"contrasts")$x
## [1] "contr.treatment"
```

- This representation allows fitting a separate coefficient for each group.

---

# Design matrices for more complex designs

- Matrices for more complex designs can be built easily by

  - First creating the corresponding factors with their levels and then
  - Applying model.matrix on a formula that describes the design

- For example for a `\(2\times2\)` design without interaction::


```r
x &lt;- factor(c(1,1,1,1,2,2,2,2))
y &lt;- factor(c("a","a","b","b","a","a","b","b"))
mm&lt;- model.matrix(~ x + y)
```

- We could say that this linear model accounts for differences in both the x and y variables.
- We assume in the above model specification, that the effect of the x and y variables are simply additive. Being in group 2 and group b is equal to the difference between 2 and 1 and the difference between b and a.

---


```r
x &lt;- factor(c(1,1,1,1,2,2,2,2))
y &lt;- factor(c("a","a","b","b","a","a","b","b"))
model.matrix(~ 0+ x + y)
```

```
##   x1 x2 yb
## 1  1  0  0
## 2  1  0  0
## 3  1  0  1
## 4  1  0  1
## 5  0  1  0
## 6  0  1  0
## 7  0  1  1
## 8  0  1  1
## attr(,"assign")
## [1] 1 1 2
## attr(,"contrasts")
## attr(,"contrasts")$x
## [1] "contr.treatment"
## 
## attr(,"contrasts")$y
## [1] "contr.treatment"
```

- Notice that adding a 0 term only provides two columns for the first factor

---

class: inverse, middle, center

name: limma

# Linear Models for Microarray Data &lt;a id="limma"&gt;&lt;/a&gt;

---

# Linear models for microarray data

- For the analysis of omics data a very popular option is the `limma` package.

- `limma` extends some R functionalities to make them easy to use in the analysis of omics data using linear models.

- Besides this it includes extensions to the standard linear model to improve analysis capabilities.

- In the following we show

  - How to create a design matrix from a "targets" file containing information on groups.
  - How to create a contrasts matrix to define the comparisons to be done.
    -   How to do the comparisons and how to interpret the resulting analysis tables.

---

# Example: Comparison between three types of breast cancer

- This example study is based on a paper published in  http://www.ncbi.nlm.nih.gov/pubmed/15897907 whose data are available in GEO as series GSE1561 series on the following link
http://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc=GSE1561

- The researchers investigated three types of breast cancer tumors: apocrine (APO), basal (BAS) and luminal (LUMI). 

- The classification is based on the resistance of tumors to estrogen and androgen receptors.

  - Tumors classified as "APO" are negative for estrogen receptor (ER-) and positive for the androgen receptor (AR+).
  - Those classified as "LUMI" are ER + and AR + and
  - Those classified as "BAS" are ER- and AR.

---

# Example: Identifying groups and comparisons

- The assignment of each sample to an experimental group can be obtained from this link:
http://www.ncbi.nlm.nih.gov/geo/gds/profileGraph.cgi?gds=1329

- Obviously this is an observational study but its analysis can be done using a linear model approach as well.

- We will usualñy proceed in three steps:

1. Identify the experimental factors and their levels.
2. Write the design matrix associated with this study design.
3. Build the contrast matrix that defines the comparisons we are interested in.

- In this example we have identified three groups and we wish to compare each tumor type with the oher two

    1. "APO" vs “LUMI”
    2. “APO" vs “BAS”
    3. “LUMI" vas "BAS"

---

# Defining the groups



```r
library (limma)
targetsLocation&lt;- "https://raw.githubusercontent.com/alexsanchezpla/Ejemplo_de_MDA_con_Bioconductor/master/data/targets.txt"
targets&lt;- read.delim(targetsLocation, row.names=1)
head(targets)
```

```
##                Sample             Ids SampleIDs Group Apocrine.grade
## GSM26878.CEL GSM26878 PF14 EnPnT2N1G2      PF14     A              3
## GSM26883.CEL GSM26883 PF19 EnPuT4N0Gu      PF19     A              2
## GSM26887.CEL GSM26887 PF23 EnPnT2N0G2      PF23     A              3
## GSM26903.CEL GSM26903 PF39 EnPuT4N0Gu      PF39     A              3
## GSM26910.CEL GSM26910 PF46 EnPnT4N1G3      PF46     A              3
## GSM26888.CEL GSM26888 PF24 EnPnTiN0G3      PF24     B              2
##              AR.repeat.length
## GSM26878.CEL               18
## GSM26883.CEL               18
## GSM26887.CEL               18
## GSM26903.CEL               17
## GSM26910.CEL               19
## GSM26888.CEL               NA
```

---

# Creating the design matrix


```r
design&lt;-matrix(
  c(1,1,1,1,1,0,0,0,0,0,0,0,0,0,0,
    0,0,0,0,0,1,1,1,1,1,0,0,0,0,0,
    0,0,0,0,0,0,0,0,0,0,1,1,1,1,1),
  nrow=15,byrow=F)
colnames(design) &lt;-c("A", "B", "L")
rownames(design)&lt;-  targets$Sample 
print(design)
```

```
##          A B L
## GSM26878 1 0 0
## GSM26883 1 0 0
## GSM26887 1 0 0
## GSM26903 1 0 0
## GSM26910 1 0 0
## GSM26888 0 1 0
## GSM26889 0 1 0
## GSM26892 0 1 0
## GSM26898 0 1 0
## GSM26906 0 1 0
## GSM26879 0 0 1
## GSM26896 0 0 1
## GSM26897 0 0 1
## GSM26907 0 0 1
## GSM26911 0 0 1
```

---

# Another way to create the design matrix 


```r
design2 &lt;-model.matrix(~ 0+targets$Group)
colnames(design2)&lt;-c("A", "B", "L")
rownames(design2)&lt;-  targets$Sample 
print(design2)
```

```
##          A B L
## GSM26878 1 0 0
## GSM26883 1 0 0
## GSM26887 1 0 0
## GSM26903 1 0 0
## GSM26910 1 0 0
## GSM26888 0 1 0
## GSM26889 0 1 0
## GSM26892 0 1 0
## GSM26898 0 1 0
## GSM26906 0 1 0
## GSM26879 0 0 1
## GSM26896 0 0 1
## GSM26897 0 0 1
## GSM26907 0 0 1
## GSM26911 0 0 1
## attr(,"assign")
## [1] 1 1 1
## attr(,"contrasts")
## attr(,"contrasts")$`targets$Group`
## [1] "contr.treatment"
```

---

# Defining the questions: The contrast matrix


```r
cont.matrix &lt;- makeContrasts (
  AvsB = B-A,
  AvsL = L-A,
  BvsL = L-B,
  levels=design)
cont.matrix
```

```
##       Contrasts
## Levels AvsB AvsL BvsL
##      A   -1   -1    0
##      B    1    0   -1
##      L    0    1    1
```

---

# Fitting the model and estimating the contrasts

- Once we have the design and contrast matrices we can proceed to estimate the model fit the contrasts and check the results

- Here we first need the data.


```r
dataLocation&lt;- "https://raw.githubusercontent.com/alexsanchezpla/Ejemplo_de_MDA_con_Bioconductor/master/results/Datos.Normalizados.Filtrados.csv2"
dataMatrix &lt;- read.csv2(dataLocation, row.names = 1)
colnames(dataMatrix)==rownames(targets)
```

```
##  [1] TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE TRUE
```

```r
dim(dataMatrix)
```

```
## [1] 6201   15
```

---

# Fit the model and the contrasts


```r
require(limma)
fit&lt;-lmFit(dataMatrix, design)
fit.main&lt;-contrasts.fit(fit, cont.matrix)
fit.main&lt;-eBayes(fit.main)
```

----

# Results are in "topTables"


```r
topTab_AvsB &lt;- topTable (fit.main, number=nrow(fit.main), coef="AvsB", adjust="fdr")
head(topTab_AvsB)
```

```
##                 logFC  AveExpr          t      P.Value    adj.P.Val         B
## 204667_at   -3.038344 8.651157 -14.338491 5.758201e-11 3.570660e-07 14.654208
## 215729_s_at  3.452290 6.137595  12.805722 3.406870e-10 1.056300e-06 13.162737
## 220192_x_at -3.016315 9.521883 -10.852451 4.304210e-09 6.846708e-06 10.938163
## 214451_at   -5.665059 7.432823 -10.833890 4.416519e-09 6.846708e-06 10.915058
## 217528_at   -5.622086 6.763101  -9.670746 2.379541e-08 2.951106e-05  9.384907
## 217284_x_at -4.313116 9.133307  -9.530910 2.942044e-08 3.040603e-05  9.189568
```

```r
# topTab_AvsL &lt;- topTable (fit.main, number=nrow(fit.main), coef="AvsL", adjust="fdr"); head(topTab_AvsL)
# topTab_BvsL  &lt;- topTable (fit.main, number=nrow(fit.main) , coef="BvsL", adjust="fdr"); head(topTab_BvsL)
```

---

# Volcano plots provide visualization


```r
volcanoplot(fit.main, coef="AvsB", highlight=10)
```

![](Linear-Models-for-Differential-Expression_files/figure-html/showResults-1.png)&lt;!-- --&gt;

```r
# volcanoplot(fit.main, coef="AvsL", highlight=10)
# volcanoplot(fit.main, coef="BvsL", highlight=10)
```

---

class: inverse, middle, center

name: exercises

# Exercises &lt;a id="exercises"&gt;&lt;/a&gt;

- You can go through the exercises in the document "Exercises on linear models for microarrays"

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
